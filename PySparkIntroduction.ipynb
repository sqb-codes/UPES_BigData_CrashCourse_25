{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16817ae4-dbe0-441f-806a-35ea5c8e4309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d764beb-0bd0-445a-b5e2-06ff56a6a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SparkContext - Entry point to PySpark Functionality\n",
    "# SparkSession - Entry point to work RDD\n",
    "    # it was introduced in version 2.0\n",
    "    # replaced SQLContext, HiveContext\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2ffe8d8-28aa-4a6d-a362-63dab94dbc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "os.environ[\"PYSPARK_PYTHON\"] =sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15cade17-50cb-4e29-ba8e-978907d7f726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/08 20:02:27 WARN Utils: Your hostname, Ravikants-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.1.10 instead (on interface en0)\n",
      "25/04/08 20:02:27 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/08 20:02:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# master() - if you are running it on clusted you need to use master name\n",
    "# ideally it would be either YARN or Mesos\n",
    "\n",
    "# local[x] - when running in standalone mode\n",
    "# x - how many partitions it should create with rdd\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[1]\").appName(\"testApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2574b38e-bb2c-4c16-9af0-81275e8d6041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x17d12bd70>\n"
     ]
    }
   ],
   "source": [
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d00bdf9-7274-4a6c-81fb-00d9713cc7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.10:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[1]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>testApp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x17d12bd70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "426cc0a2-d579-443d-bd6d-e1f562025a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    (101, \"John\", 56000, \"Male\", 2),\n",
    "    (102, \"Sam\", 65000, \"Male\", 1),\n",
    "    (103, \"Max\", 50000, \"Male\", 3),\n",
    "    (104, \"Nick\", 80000, \"Male\", 0),\n",
    "    (105, \"Sneha\", 25000, \"Female\", 5),\n",
    "    (106, \"Neha\", 50000, \"Female\", 1),\n",
    "    (107, \"Monica\", 30000, \"Female\", 2),\n",
    "    (108, \"Adam\", 150000, \"Male\", 3),\n",
    "    (109, \"Alex\", 100000, \"Male\", 3),\n",
    "    (110, \"Smith\", 90000, \"Male\", 1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0510454-b82d-436b-aa18-bd707233de68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDD - Resilient Distributed Dataset\n",
    "# - fundamental data structure of PySpark that in fault-tolerant\n",
    "# - distributed collections of objects\n",
    "# - immutable - once created cannot be changed\n",
    "\n",
    "rdd = spark.sparkContext.parallelize(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f49741da-5674-4e2f-94e5-9b720f48c5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:289"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "765784d6-df4c-4dab-bdd4-d6b6f558ecfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de5c207b-0e07-4375-8891-3a38508f9f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(101, 'John', 56000, 'Male', 2),\n",
       " (102, 'Sam', 65000, 'Male', 1),\n",
       " (103, 'Max', 50000, 'Male', 3),\n",
       " (104, 'Nick', 80000, 'Male', 0),\n",
       " (105, 'Sneha', 25000, 'Female', 5),\n",
       " (106, 'Neha', 50000, 'Female', 1),\n",
       " (107, 'Monica', 30000, 'Female', 2),\n",
       " (108, 'Adam', 150000, 'Male', 3),\n",
       " (109, 'Alex', 100000, 'Male', 3),\n",
       " (110, 'Smith', 90000, 'Male', 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b806eddc-2a49-4418-acd6-59b306b2ffad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+------+---+\n",
      "| _1|    _2|    _3|    _4| _5|\n",
      "+---+------+------+------+---+\n",
      "|101|  John| 56000|  Male|  2|\n",
      "|102|   Sam| 65000|  Male|  1|\n",
      "|103|   Max| 50000|  Male|  3|\n",
      "|104|  Nick| 80000|  Male|  0|\n",
      "|105| Sneha| 25000|Female|  5|\n",
      "|106|  Neha| 50000|Female|  1|\n",
      "|107|Monica| 30000|Female|  2|\n",
      "|108|  Adam|150000|  Male|  3|\n",
      "|109|  Alex|100000|  Male|  3|\n",
      "|110| Smith| 90000|  Male|  1|\n",
      "+---+------+------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd.toDF().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72b484cb-0c21-4f83-9397-a68ef0fdea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"ID\",\"Name\",\"Salary\",\"Gender\",\"Leaves\"]\n",
    "df = rdd.toDF(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02155354-0ebc-4523-ac38-c0d3e30a3f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+------+------+\n",
      "| ID|  Name|Salary|Gender|Leaves|\n",
      "+---+------+------+------+------+\n",
      "|101|  John| 56000|  Male|     2|\n",
      "|102|   Sam| 65000|  Male|     1|\n",
      "|103|   Max| 50000|  Male|     3|\n",
      "|104|  Nick| 80000|  Male|     0|\n",
      "|105| Sneha| 25000|Female|     5|\n",
      "|106|  Neha| 50000|Female|     1|\n",
      "|107|Monica| 30000|Female|     2|\n",
      "|108|  Adam|150000|  Male|     3|\n",
      "|109|  Alex|100000|  Male|     3|\n",
      "|110| Smith| 90000|  Male|     1|\n",
      "+---+------+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43d31fb3-e359-43c4-a4b3-13bbcbf8ecef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: long (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Salary: long (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Leaves: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da2f62d4-2a44-4d75-990c-40544ed1d680",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, IntegerType, StructField, StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98dd8c4e-00ca-4821-9def-61d45c7e04aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"EmpId\", IntegerType()),\n",
    "    StructField(\"EmpName\",StringType()),\n",
    "    StructField(\"EmpSalary\", IntegerType()),\n",
    "    StructField(\"Gender\", StringType()),\n",
    "    StructField(\"EmpLeaves\", IntegerType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1f7c5fc-c0cd-45e5-974c-1e4a07cd3036",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = spark.createDataFrame(data=dataset, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "755436a6-88a3-459d-aa09-e961afc6fbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+---------+------+---------+\n",
      "|EmpId|EmpName|EmpSalary|Gender|EmpLeaves|\n",
      "+-----+-------+---------+------+---------+\n",
      "|  101|   John|    56000|  Male|        2|\n",
      "|  102|    Sam|    65000|  Male|        1|\n",
      "|  103|    Max|    50000|  Male|        3|\n",
      "|  104|   Nick|    80000|  Male|        0|\n",
      "|  105|  Sneha|    25000|Female|        5|\n",
      "|  106|   Neha|    50000|Female|        1|\n",
      "|  107| Monica|    30000|Female|        2|\n",
      "|  108|   Adam|   150000|  Male|        3|\n",
      "|  109|   Alex|   100000|  Male|        3|\n",
      "|  110|  Smith|    90000|  Male|        1|\n",
      "+-----+-------+---------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "159257a8-a787-4d3b-aecb-98530fc19dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- EmpId: integer (nullable = true)\n",
      " |-- EmpName: string (nullable = true)\n",
      " |-- EmpSalary: integer (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- EmpLeaves: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "940d9508-85d7-4b83-ab64-a0837e8f7208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1602866-a5f0-41f8-ba81-a50f6f642ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+---------+------+---------+\n",
      "|EmpId|EmpName|EmpSalary|Gender|EmpLeaves|\n",
      "+-----+-------+---------+------+---------+\n",
      "|  101|   John|    56000|  Male|        2|\n",
      "|  102|    Sam|    65000|  Male|        1|\n",
      "|  103|    Max|    50000|  Male|        3|\n",
      "+-----+-------+---------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.limit(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8ec97c7-4496-4fd5-87ae-6f6e205358d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmpId</th>\n",
       "      <th>EmpName</th>\n",
       "      <th>EmpSalary</th>\n",
       "      <th>Gender</th>\n",
       "      <th>EmpLeaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>John</td>\n",
       "      <td>56000</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>Sam</td>\n",
       "      <td>65000</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>Max</td>\n",
       "      <td>50000</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EmpId EmpName  EmpSalary Gender  EmpLeaves\n",
       "0    101    John      56000   Male          2\n",
       "1    102     Sam      65000   Male          1\n",
       "2    103     Max      50000   Male          3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dfae745a-1206-44e7-b90f-d29ffdb67dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|EmpName|EmpSalary|\n",
      "+-------+---------+\n",
      "|   John|    56000|\n",
      "|    Sam|    65000|\n",
      "|    Max|    50000|\n",
      "+-------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.select(\"EmpName\", \"EmpSalary\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6601eea6-1cde-41b7-bb73-9cf88d4ebb46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
